import keras
from keras.models import Sequential
from keras.layers import merge
from keras.models import Model
from keras.layers import Input, merge, BatchNormalization, Activation, Deconvolution2D
from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D
from keras.optimizers import SGD
from keras.applications import vgg16
import numpy as np
from keras import backend as K
from keras.preprocessing.image import load_img, img_to_array
import math
from keras.regularizers import Regularizer

'''
IMPORTANT: This used Theano as backend and use channel last data format!
Image is representing as (1, 256, 256, 3)
'''

def process_image(image_path):
    '''
    Preprocess image for VGG 16
    subtract mean pixel value and resize to 256*256
    '''
    img = load_img(image_path, target_size=(WIDTH, HEIGHT))
    img = img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = vgg16.preprocess_input(img)
    return img


class ContentLossRegularizer(Regularizer):
    def __init__(self, weight=1.0):
        self.weight = weight
        super(ContentLossRegularizer, self).__init__()

    def __call__(self, x):
        new_activation = x.output[0] # Generated by network features
        content_activation = x.output[2] # True X input features
        loss = self.get_content_loss(new_activation, content_activation)
        return loss

    def get_content_loss(self, new_activation, content_activation):
        return K.mean(K.square(new_activation - content_activation))


class SytleRegularizer(Regularizer):
    def __init__(self, weight=1.0):
        self.weight = weight
        super(SytleRegularizer, self).__init__()

    def __call__(self, x):
        print x
        new_activation = x.output[0]  # Generated by network features
        style_activation = x.output[1]  # True X input features
        loss = self.get_style_loss(new_activation, style_activation)
        return loss

    def get_style_loss(self, new_activation, style_activation):
        original_gram_matrix = self.gram_matrix(style_activation[0])
        new_gram_matrix = self.gram_matrix(new_activation[0])
        return K.sum(K.square(original_gram_matrix - new_gram_matrix))

    def gram_matrix(self, activation):
        assert K.ndim(activation) == 3
        shape = K.shape(activation)
        shape = (shape[0] * shape[1], shape[2])
        # reshape to (H*W, C)
        activation = K.reshape(activation, shape)
        return K.dot(K.transpose(activation), activation) / (shape[0] * shape[1])


class TVRegularizer(Regularizer):
    def __init__(self, weight=1.0):
        self.weight = weight
        super(TVRegularizer, self).__init__()
        self.WIDTH = 256
        self.HEIGHT = 256

    def __call__(self, x):
        loss = self.get_TV(x)
        return loss

    def get_TV(self, image):
        print image
        print K.ndim(image)
        assert K.ndim(image) == 4
        x_diff = K.square(image[:, :self.WIDTH - 1, :self.HEIGHT - 1, :] - image[:, 1:, :self.HEIGHT - 1, :])
        y_diff = K.square(image[:, :self.WIDTH - 1, :self.HEIGHT - 1, :] - image[:, :self.WIDTH - 1, 1:, :])
        return TV_WEIGHT * K.mean(K.sum(K.pow(x_diff + y_diff, 1.25)))


def get_vgg_activation(tensor, layer_name):
    model = vgg16.VGG16(input_tensor=tensor, weights='imagenet', include_top=False)
    outputs_dict = {}
    for layer in model.layers:
        outputs_dict[layer.name] = layer.output
        layer.trainable = False
    return outputs_dict[layer_name]

def dummy_loss_function(y_true, y_pred):
    return get_TV(y_pred)


def get_TV(image):
    assert K.ndim(image) == 3
    x_diff = K.square(image[:, :WIDTH - 1, :HEIGHT - 1, :] - image[:, 1:, :HEIGHT - 1, :])
    y_diff = K.square(image[:, :WIDTH - 1, :HEIGHT - 1, :] - image[:, :WIDTH - 1, 1:, :])
    return TV_WEIGHT * K.mean(K.sum(K.pow(x_diff + y_diff, 1.25)))

def zero_loss_function(y_true, y_pred):
    # return K.sum(y_pred)
    return K.variable(np.zeros(1,))


def residual_block(x):
    shortcut = x
    x = Convolution2D(128, 3, 3, activation='linear', border_mode='same')(x)
    x = BatchNormalization(axis=1)(x)
    x = Activation('relu')(x)
    x = Convolution2D(128, 3, 3, activation='linear', border_mode='same')(x)
    x = BatchNormalization(axis=1)(x)
    m = merge([x, shortcut], mode='sum')
    return m


WIDTH = 256
HEIGHT = 256
TV_WEIGHT = math.pow(10, -6)


def get_loss_model():
    original = Input(shape=(WIDTH, HEIGHT, 3))
    content = Input(shape=(WIDTH, HEIGHT, 3))
    style =  Input(shape=(WIDTH, HEIGHT, 3))

    c1 = Convolution2D(32, 9, 9, activation='linear', border_mode='same')(original)
    c1 = BatchNormalization(axis=1)(c1)
    c1 = Activation('relu')(c1)

    c2 = Convolution2D(64, 3, 3, activation='linear', border_mode='same',
                       subsample=(2, 2))(c1)
    c2 = BatchNormalization(axis=1)(c2)
    c2 = Activation('relu')(c2)

    c3 = Convolution2D(128, 3, 3, activation='linear', border_mode='same',
                       subsample=(2, 2))(c2)
    c3 = BatchNormalization(axis=1)(c3)
    c3 = Activation('relu')(c3)

    r1 = residual_block(c3)
    r2 = residual_block(r1)
    r3 = residual_block(r2)
    r4 = residual_block(r3)
    r5 = residual_block(r4)

    d1 = Deconvolution2D(64, 3, 3, activation='linear', border_mode='same',
                         subsample=(2, 2), output_shape=(1, 128, 128))(r5)

    d2 = Deconvolution2D(32, 3, 3, activation='linear', border_mode='same',
                         subsample=(2, 2), output_shape=(1, 256, 256))(d1)

    c4 = Convolution2D(3, 9, 9, activation='relu', name='output', border_mode='same', activity_regularizer=TVRegularizer())(d2)

    input = merge([c4, style, content], mode='concat', concat_axis=0)

    x = Convolution2D(64, 3, 3, activation='relu', name='block1_conv1', border_mode='same')(input)
    x = Convolution2D(64, 3, 3, activation='relu', name='block1_conv2', border_mode='same')(x)

    x = MaxPooling2D((2, 2), strides=(2, 2), name = 'block1_pool')(x)

    x = Convolution2D(128, 3, 3, activation='relu', name='block2_conv1', border_mode='same')(x)
    x = Convolution2D(128, 3, 3, activation='relu', name='block2_conv2', border_mode='same', activity_regularizer=ContentLossRegularizer())(x)

    x = MaxPooling2D((2, 2), strides=(2, 2), name = 'block2_pool')(x)

    x = Convolution2D(256, 3, 3, activation='relu', name='block3_conv1', border_mode='same')(x)
    x = Convolution2D(256, 3, 3, activation='relu', name='block3_conv2', border_mode='same')(x)
    x = Convolution2D(256, 3, 3, activation='relu', name='block3_conv3', border_mode='same', activity_regularizer=SytleRegularizer())(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name = 'block3_pool')(x)

    x = Convolution2D(512, 3, 3, activation='relu', name='block4_conv1', border_mode='same')(x)
    x = Convolution2D(512, 3, 3, activation='relu', name='block4_conv2', border_mode='same')(x)

    x = Convolution2D(512, 3, 3, activation='relu', name='block4_conv3', border_mode='same')(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name = 'block4_pool')(x)

    x = Convolution2D(512, 3, 3, activation='relu', name='block5_conv1', border_mode='same')(x)
    x = Convolution2D(512, 3, 3, activation='relu', name='block5_conv2', border_mode='same')(x)
    x = Convolution2D(512, 3, 3, activation='relu', name='block5_conv3', border_mode='same')(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name = 'block5_pool')(x)

    model = Model([original, style, content], [c4])
    model_layers = {layer.name : layer for layer in model.layers}
    original_vgg = vgg16.VGG16(weights='imagenet', include_top=False)
    original_vgg_layers = {layer.name : layer for layer in original_vgg.layers}

    # load weight
    for layer in original_vgg.layers:
        if layer.name in model_layers:
            # print layer.name, model_layers[layer.name].output_shape
            model_layers[layer.name].set_weights(original_vgg_layers[layer.name].get_weights())
            model_layers[layer.name].trainable = False

    print "VGG model built successfully!"
    return model


# layers
content_layers = ['block2_conv2']
style_layers = ['block1_conv2', 'block2_conv2',
                  'block3_conv3', 'block4_conv3']


# input image
content = process_image("./image/baby.jpg")
style = process_image('./image/style.jpg')
transfer = process_image('./image/tranfered.jpg')
content_tensor = K.variable(content)
style_tensor = K.variable(style)
transfer_tensor = K.variable(transfer)

# define a model
model = get_loss_model()

for layer in model.layers:
    print layer.name, layer.output_shape

model.compile(loss={'output': zero_loss_function},
              optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0))

# print content.shape
# print style.shape
# print transfer.shape
#
# c = model([transfer_tensor, style_tensor, content_tensor])
# print c
# print c.eval().shape
